#!/usr/bin/env python3
# encoder.py
"""
Encoder script for DCVC video model (frame-by-frame).

Example:
  PYTHONPATH=$PWD python encoder.py \
    --frames-dir data/frames/train/clip_01 \
    --out-dir encoded/clip_01_bits \
    --ckpt ./checkpoints_finetune_lambda0.01/best_epoch010.pth.tar \
    --qp 0 --device cuda --dpb-refresh 50
"""

import os
import sys
import json
import argparse
from glob import glob
from pathlib import Path
from tqdm import tqdm

import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image

# Attempt to import model (repo root must be on PYTHONPATH)
try:
    from src.models.video_model import DMC as VideoModel
except Exception as e:
    print("ERROR: failed to import VideoModel from src.models.video_model:", e, file=sys.stderr)
    raise

def pad_to_multiple(x, mult=16):
    # x: torch tensor [1,C,H,W]
    _, _, H, W = x.shape
    pad_h = (mult - (H % mult)) % mult
    pad_w = (mult - (W % mult)) % mult
    if pad_h == 0 and pad_w == 0:
        return x, (0,0)
    pad = (0, pad_w, 0, pad_h)  # (left, right, top, bottom)
    x_padded = F.pad(x, pad, mode='replicate')
    return x_padded, (pad_h, pad_w)

def load_checkpoint_into_model(model, ckpt_path):
    ck = torch.load(ckpt_path, map_location='cpu')
    sd = ck.get('state_dict', ck)
    # handle 'module.' prefix
    sd = {k.replace('module.', ''): v for k,v in sd.items()}
    model.load_state_dict(sd, strict=False)

def main():
    p = argparse.ArgumentParser()
    p.add_argument('--frames-dir', required=True, help="Directory with input frames (PNG/JPG).")
    p.add_argument('--out-dir', required=True, help="Directory to write encoded bitstreams + manifest.")
    p.add_argument('--ckpt', required=True, help="Path to trained checkpoint (.pth.tar).")
    p.add_argument('--qp', type=int, default=0, help="QP index to use (0..63).")
    p.add_argument('--device', default='cuda', help="Device to run on (cuda or cpu).")
    p.add_argument('--dpb-refresh', type=int, default=0,
                   help="If >0, reset DPB every N frames (simulated I-frame).")
    p.add_argument('--ext', default='png', help="Extension to search for (default png).")
    args = p.parse_args()

    frames_dir = Path(args.frames_dir)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # gather frames
    frames = sorted(glob(str(frames_dir / f"*.{args.ext}")))
    if len(frames) == 0:
        print("No frames found in", frames_dir)
        return

    device = torch.device(args.device if (args.device == 'cpu' or torch.cuda.is_available()) else 'cpu')
    print("device:", device)

    # load model
    model = VideoModel().to(device).eval()
    if os.path.exists(args.ckpt):
        try:
            load_checkpoint_into_model(model, args.ckpt)
            print("Loaded checkpoint:", args.ckpt)
        except Exception as e:
            print("Warning: failed to load checkpoint:", e)
    else:
        print("Warning: checkpoint not found:", args.ckpt)

    # try to update entropy coder (not critical)
    try:
        model.update()
    except Exception:
        # compiled entropy coder may be missing; continue without raising
        print("model.update() failed or not needed (continuing without compiled coder).")

    # ensure dpb exists and initialize empty (first frame we'll add zeros with correct pad)
    try:
        model.clear_dpb()
    except Exception:
        model.dpb = []

    manifest = {
        "num_frames": len(frames),
        "qp": int(args.qp),
        "frame_meta": []
    }

    for i, fp in enumerate(tqdm(frames, desc="Encoding frames")):
        im = Image.open(fp).convert("RGB")
        arr = np.asarray(im, dtype=np.float32) / 255.0
        H, W = arr.shape[0], arr.shape[1]

        x = torch.from_numpy(arr.transpose(2,0,1))[None,...].to(device)  # [1,C,H,W]
        x_padded, (pad_h, pad_w) = pad_to_multiple(x, mult=16)

        # For first frame, initialize dpb with zero reference frame of same padded size
        if i == 0:
            zeros = torch.zeros_like(x_padded)
            try:
                model.clear_dpb()
            except Exception:
                model.dpb = []
            try:
                model.add_ref_frame(frame=zeros, increase_poc=False)
            except TypeError:
                # fallback signature variations
                try:
                    model.add_ref_frame(feature=None, frame=zeros, increase_poc=False)
                except Exception:
                    model.dpb = []
                    model.add_ref_frame(frame=zeros, increase_poc=False)
            except Exception:
                # ignore
                pass

        # Optionally simulate I-frame / dpb refresh every N frames
        if args.dpb_refresh > 0 and (i > 0) and (i % args.dpb_refresh == 0):
            try:
                model.clear_dpb()
                zeros = torch.zeros_like(x_padded)
                model.add_ref_frame(frame=zeros, increase_poc=False)
                print(f"--- DPB reset at frame {i} (simulated I-frame) ---")
            except Exception as e:
                print(f"DPB reset failed at frame {i}: {e}")

        # compress
        bit_stream = None
        success = False
        try:
            out = model.compress(x_padded, int(args.qp))
            # compress should return {'bit_stream': bytes, ...}
            if isinstance(out, dict) and 'bit_stream' in out:
                bit_stream = out['bit_stream']
                success = True
            else:
                # Some image models return x_hat directly; treat as no-bitstream
                bit_stream = b''
                success = False
        except Exception as e:
            # If compress fails, warn and continue (we still write a placeholder empty stream)
            print(f"Warning: model.compress() failed for frame {i}: {e}")
            bit_stream = b''
            success = False

        # save bitstream bytes to file
        bin_fname = out_dir / f"frame_{i:05d}.bin"
        try:
            with open(bin_fname, 'wb') as f:
                if isinstance(bit_stream, (bytes, bytearray)):
                    f.write(bit_stream)
                elif hasattr(bit_stream, 'tobytes'):
                    # e.g., numpy array
                    f.write(bit_stream.tobytes())
                elif bit_stream is None:
                    pass
                else:
                    # try to convert to bytes
                    try:
                        f.write(bytes(bit_stream))
                    except Exception:
                        # fallback: write nothing
                        pass
        except Exception as e:
            print(f"Failed to write bitstream for frame {i} to {bin_fname}: {e}")

        # Assemble per-frame metadata to manifest
        manifest["frame_meta"].append({
            "index": i,
            "filename": str(bin_fname.name),
            "orig_height": int(H),
            "orig_width": int(W),
            "pad_h": int(pad_h),
            "pad_w": int(pad_w),
            "qp": int(args.qp),
            "had_bitstream": bool(success)
        })

    # Save manifest
    manifest_path = out_dir / "manifest.json"
    with open(manifest_path, 'w') as f:
        json.dump(manifest, f, indent=2)

    print("Encoding complete. Wrote", len(manifest["frame_meta"]), "bitstreams to", out_dir)
    print("Manifest saved to", manifest_path)

if __name__ == "__main__":
    main()
