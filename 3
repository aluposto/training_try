# live_padded_reconstruct_clip.py (for Jupyter notebook)
import os, math, glob, time
import numpy as np
from PIL import Image
import torch
import torch.nn.functional as F
from src.models.video_model import DMC as VideoModel

# display helpers
from IPython.display import display, clear_output
import matplotlib
# prefer inline backend (not required if you already have it)
matplotlib.use('module://matplotlib_inline.backend_inline')
import matplotlib.pyplot as plt

# Paths - edit if needed
ckpt_path = "./checkpoints_finetune_lambda0.01/best_epoch010.pth.tar"
frames_dir = "data/frames/train/clip_01"   # update as needed
out_dir = "outputs/recon_frames/clip_01_padded_live"
os.makedirs(out_dir, exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

# Load model
model = VideoModel().to(device).eval()
if os.path.exists(ckpt_path):
    ck = torch.load(ckpt_path, map_location="cpu")
    sd = ck.get("state_dict", ck)
    model.load_state_dict({k.replace("module.",""): v for k,v in sd.items()}, strict=False)
    print("Loaded checkpoint:", ckpt_path)
else:
    print("Warning: checkpoint not found:", ckpt_path)

def mse_to_psnr(mse, max_val=1.0):
    if not np.isfinite(mse): return float('nan')
    if mse == 0: return float('inf')
    return 10.0 * math.log10((max_val**2) / mse)

# get frames
frame_paths = sorted(glob.glob(os.path.join(frames_dir, "*.png")))
if len(frame_paths) == 0:
    raise SystemExit(f"No frames found in {frames_dir}")

# init dpb
try:
    model.clear_dpb()
except Exception:
    model.dpb = []

psnr_list = []
mse_list = []

# Prepare a figure once
fig, ax = plt.subplots(figsize=(10,3))
ax.set_title("PSNR per frame (live)")
ax.set_xlabel("frame index")
ax.set_ylabel("PSNR (dB)")
ax.grid(True)
line, = ax.plot([], [], marker='o', markersize=2)
ax.set_xlim(0, max(10, len(frame_paths)))
ax.set_ylim(0, 50)
display(fig)   # show initial empty figure

start_time = time.time()
for i, p in enumerate(frame_paths):
    im = Image.open(p).convert("RGB")
    arr = np.asarray(im, dtype=np.float32)/255.0
    H, W = arr.shape[0], arr.shape[1]
    pad_h = (16 - (H % 16)) % 16
    pad_w = (16 - (W % 16)) % 16
    pad = (0, pad_w, 0, pad_h)
    x = torch.from_numpy(arr.transpose(2,0,1))[None,...].to(device)
    x_padded = F.pad(x, pad, mode='replicate') if (pad_w or pad_h) else x

    # init dpb zero frame to padded size for first frame
    if i == 0:
        zeros = torch.zeros_like(x_padded)
        try:
            model.clear_dpb()
        except Exception:
            model.dpb = []
        try:
            model.add_ref_frame(frame=zeros, increase_poc=False)
        except Exception:
            try:
                model.add_ref_frame(feature=None, frame=zeros, increase_poc=False)
            except Exception:
                model.dpb = []
                try:
                    model.add_ref_frame(frame=zeros, increase_poc=False)
                except Exception:
                    pass

    # inference (best-effort differentiable path)
    with torch.no_grad():
        try:
            feat_adapt = model.apply_feature_adaptor()
        except Exception:
            try:
                feat_in = F.pixel_unshuffle(x_padded, 8)
            except Exception:
                feat_in = x_padded
            try:
                feat_adapt = model.feature_adaptor_i(feat_in)
            except Exception:
                feat_adapt = feat_in

        ctx = None; ctx_t = None
        if hasattr(model, "feature_extractor"):
            try:
                qf = model.q_feature[0:1] if hasattr(model,"q_feature") else None
                ctx, ctx_t = model.feature_extractor(feat_adapt, qf)
            except Exception:
                ctx, ctx_t = (None, None)

        y = None
        if hasattr(model, "encoder"):
            try:
                q_enc = model.q_encoder[0:1] if hasattr(model,"q_encoder") else None
                y = model.encoder(x_padded, ctx if ctx is not None else feat_adapt, q_enc)
            except Exception:
                y = None

        x_hat_padded = x_padded
        if y is not None and hasattr(model, "decoder") and hasattr(model, "recon_generation_net"):
            try:
                q_dec = model.q_decoder[0:1] if hasattr(model,"q_decoder") else None
                q_recon = model.q_recon[0:1] if hasattr(model,"q_recon") else None
                feat_dec = model.decoder(y, ctx if ctx is not None else feat_adapt, q_dec)
                x_hat_padded = model.recon_generation_net(feat_dec, q_recon).clamp(0,1)
                # update dpb
                try:
                    model.add_ref_frame(feature=feat_dec, frame=x_hat_padded, increase_poc=True)
                except Exception:
                    try:
                        model.add_ref_frame(frame=x_hat_padded, increase_poc=True)
                    except Exception:
                        pass
            except Exception:
                x_hat_padded = x_padded

    x_hat = x_hat_padded[..., :H, :W]

    # sanitize numerical issues
    x_hat_np = x_hat[0].cpu().numpy().transpose(1,2,0)
    x_hat_np = np.nan_to_num(x_hat_np, nan=0.0, posinf=1.0, neginf=0.0)
    x_hat_np = np.clip(x_hat_np, 0.0, 1.0)
    x_hat = torch.from_numpy(x_hat_np.transpose(2,0,1))[None].to(device)

    mse = F.mse_loss(x_hat, x, reduction="mean").item()
    psnr = mse_to_psnr(mse)
    mse_list.append(mse)
    psnr_list.append(psnr)

    # save small preview if you want
    out_np = (x_hat_np * 255.0).round().astype(np.uint8)
    Image.fromarray(out_np).save(os.path.join(out_dir, f"frame_{i:05d}.png"))

    # --- UPDATE LIVE PLOT by re-drawing and forcing notebook to display it ---
    line.set_xdata(np.arange(len(psnr_list)))
    line.set_ydata(np.array(psnr_list))
    ax.relim()
    ax.autoscale_view()
    # draw canvas
    fig.canvas.draw()
    # clear previous output and display updated figure (real-time effect)
    clear_output(wait=True)
    display(fig)

    # small pause to allow UI loop to refresh (0.01 is usually enough)
    plt.pause(0.01)

    # optional small log
    if i % 50 == 0:
        elapsed = time.time() - start_time
        print(f"frame {i}/{len(frame_paths)}  psnr={psnr:.2f}  avg_psnr={(np.nanmean(psnr_list)):.2f}  elapsed={elapsed:.1f}s")

# end loop
plt.ioff()
# final save of the PSNR plot
finite_psnrs = [p for p in psnr_list if np.isfinite(p)]
avg_mse = float(np.mean(mse_list))
avg_psnr = float(np.mean(finite_psnrs)) if len(finite_psnrs)>0 else float('nan')
print("Done. frames:", len(frame_paths), "avg_mse:", avg_mse, "avg_psnr (finite only):", avg_psnr)
plot_path = os.path.join(out_dir, "psnr_over_time.png")
fig.savefig(plot_path)
print("Saved PSNR plot to:", plot_path)
