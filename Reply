#!/usr/bin/env python3
"""
encoder.py - frame-by-frame encoder that handles missing compiled entropy coder.

Usage examples (run from repo root so `src` is importable):
PYTHONPATH=$PWD python encoder.py \
  --frames-dir data/frames/train/clip_01 \
  --out-dir encoded/clip_01_bits \
  --ckpt ./checkpoints_finetune_lambda0.01/best_epoch010.pth.tar \
  --qp 0 --device cuda --dpb-refresh 50
"""

import os
import sys
import json
import argparse
from glob import glob
from pathlib import Path
from tqdm import tqdm

import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image

# Import model class from repo
try:
    from src.models.video_model import DMC as VideoModel
except Exception as e:
    print("ERROR: failed to import VideoModel from src.models.video_model:", e, file=sys.stderr)
    raise

def pad_to_multiple(x, mult=16):
    _, _, H, W = x.shape
    pad_h = (mult - (H % mult)) % mult
    pad_w = (mult - (W % mult)) % mult
    if pad_h == 0 and pad_w == 0:
        return x, (0,0)
    pad = (0, pad_w, 0, pad_h)  # (left,right,top,bottom)
    x_padded = F.pad(x, pad, mode='replicate')
    return x_padded, (pad_h, pad_w)

def load_checkpoint_into_model(model, ckpt_path):
    ck = torch.load(ckpt_path, map_location='cpu')
    sd = ck.get('state_dict', ck)
    sd = {k.replace('module.', ''): v for k,v in sd.items()}
    model.load_state_dict(sd, strict=False)

def safe_model_update(model):
    """
    Try to call model.update() and sanity-check whether compressed entropy objects exist.
    Returns True if codec backend appears available, False otherwise.
    """
    try:
        model.update()
    except Exception as e:
        # update failed (likely missing compiled MLCodec extension)
        print("model.update() failed or not needed (continuing without compiled coder).", file=sys.stderr)
        # continue to check fallback cases
    # sanity check: Entropy coder objects should be present
    has_entropy = getattr(model, "entropy_coder", None) is not None
    # bit_estimator_z should also have been updated to attach to entropy coder
    be = getattr(model, "bit_estimator_z", None)
    be_ok = False
    try:
        if be is not None and getattr(be, "entropy_coder", None) is not None:
            be_ok = True
    except Exception:
        be_ok = False
    # gaussian_encoder should have entropy coder attached too
    ge = getattr(model, "gaussian_encoder", None)
    ge_ok = False
    try:
        if ge is not None and getattr(ge, "entropy_coder", None) is not None:
            ge_ok = True
    except Exception:
        ge_ok = False

    codec_ready = has_entropy or be_ok or ge_ok
    if not codec_ready:
        # try a small operation to see if compress will definitely fail: call entropy_coder.reset() if present
        try:
            if hasattr(model, "entropy_coder") and model.entropy_coder is not None:
                model.entropy_coder.reset()
                codec_ready = True
        except Exception:
            codec_ready = False

    return bool(codec_ready)

def differentiable_recon(model, x_padded):
    """
    Best-effort encoder->decoder->recon path (no entropy coder; differentiable path).
    Returns reconstructed tensor x_hat_padded (same shape as x_padded) or None on failure.
    """
    try:
        # apply feature adaptor (uses dpb[0] or feature_adaptor_i)
        try:
            feat_adapt = model.apply_feature_adaptor()
        except Exception:
            try:
                feat_in = F.pixel_unshuffle(x_padded, 8)
            except Exception:
                feat_in = x_padded
            try:
                feat_adapt = model.feature_adaptor_i(feat_in)
            except Exception:
                feat_adapt = feat_in

        ctx = None; ctx_t = None
        if hasattr(model, "feature_extractor"):
            try:
                qf = model.q_feature[0:1] if hasattr(model, "q_feature") else None
                ctx, ctx_t = model.feature_extractor(feat_adapt, qf)
            except Exception:
                ctx, ctx_t = (None, None)

        y = None
        if hasattr(model, "encoder"):
            try:
                q_enc = model.q_encoder[0:1] if hasattr(model, "q_encoder") else None
                y = model.encoder(x_padded, ctx if ctx is not None else feat_adapt, q_enc)
            except Exception:
                y = None

        x_hat_padded = x_padded
        if y is not None and hasattr(model, "decoder") and hasattr(model, "recon_generation_net"):
            try:
                q_dec = model.q_decoder[0:1] if hasattr(model, "q_decoder") else None
                q_recon = model.q_recon[0:1] if hasattr(model, "q_recon") else None
                feat_dec = model.decoder(y, ctx if ctx is not None else feat_adapt, q_dec)
                x_hat_padded = model.recon_generation_net(feat_dec, q_recon).clamp(0,1)
                # attempt to update dpb
                try:
                    model.add_ref_frame(feature=feat_dec, frame=x_hat_padded, increase_poc=True)
                except Exception:
                    try:
                        model.add_ref_frame(frame=x_hat_padded, increase_poc=True)
                    except Exception:
                        pass
            except Exception:
                x_hat_padded = x_padded
        return x_hat_padded
    except Exception as e:
        # absolute fallback
        return x_padded

def main():
    p = argparse.ArgumentParser()
    p.add_argument('--frames-dir', required=True, help="Directory with input frames (PNG/JPG).")
    p.add_argument('--out-dir', required=True, help="Directory to write encoded bitstreams + manifest.")
    p.add_argument('--ckpt', required=True, help="Path to trained checkpoint (.pth.tar).")
    p.add_argument('--qp', type=int, default=0, help="QP index to use (0..63).")
    p.add_argument('--device', default='cuda', help="Device to run on (cuda or cpu).")
    p.add_argument('--dpb-refresh', type=int, default=0,
                   help="If >0, reset DPB every N frames (simulated I-frame).")
    p.add_argument('--ext', default='png', help="Extension to search for (default png).")
    args = p.parse_args()

    frames_dir = Path(args.frames_dir)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    frames = sorted(glob(str(frames_dir / f"*.{args.ext}")))
    if len(frames) == 0:
        print("No frames found in", frames_dir)
        return

    device = torch.device(args.device if (args.device == 'cpu' or torch.cuda.is_available()) else 'cpu')
    print("device:", device)

    # load and prepare model
    model = VideoModel().to(device).eval()
    if os.path.exists(args.ckpt):
        try:
            load_checkpoint_into_model(model, args.ckpt)
            print("Loaded checkpoint:", args.ckpt)
        except Exception as e:
            print("Warning: failed to load checkpoint:", e)
    else:
        print("Warning: checkpoint not found:", args.ckpt)

    # Try update (may fail if compiled coder not installed)
    codec_ready = False
    try:
        codec_ready = safe_model_update(model)
    except Exception:
        codec_ready = False

    if codec_ready:
        print("Codec backend appears available — attempting model.compress() path.")
    else:
        print("Compiled codec backend NOT available. Falling back to differentiable recon (no real bitstreams).")

    # ensure dpb exists and initialize empty
    try:
        model.clear_dpb()
    except Exception:
        model.dpb = []

    manifest = {
        "num_frames": len(frames),
        "qp": int(args.qp),
        "frame_meta": []
    }

    for i, fp in enumerate(tqdm(frames, desc="Encoding frames")):
        im = Image.open(fp).convert("RGB")
        arr = np.asarray(im, dtype=np.float32) / 255.0
        H, W = int(arr.shape[0]), int(arr.shape[1])

        x = torch.from_numpy(arr.transpose(2,0,1))[None,...].to(device)  # [1,C,H,W]
        x_padded, (pad_h, pad_w) = pad_to_multiple(x, mult=16)

        # For first frame, init dpb with zeros matching padded size
        if i == 0:
            try:
                model.clear_dpb()
            except Exception:
                model.dpb = []
            zeros = torch.zeros_like(x_padded)
            try:
                model.add_ref_frame(frame=zeros, increase_poc=False)
            except TypeError:
                try:
                    model.add_ref_frame(feature=None, frame=zeros, increase_poc=False)
                except Exception:
                    model.dpb = []
                    try:
                        model.add_ref_frame(frame=zeros, increase_poc=False)
                    except Exception:
                        pass

        # optional DPB refresh to reduce drift
        if args.dpb_refresh > 0 and (i > 0) and (i % args.dpb_refresh == 0):
            try:
                model.clear_dpb()
                zeros = torch.zeros_like(x_padded)
                model.add_ref_frame(frame=zeros, increase_poc=False)
                print(f"--- DPB reset at frame {i} (simulated I-frame) ---")
            except Exception as e:
                print(f"DPB reset failed at frame {i}: {e}")

        had_bitstream = False
        bit_stream = b''
        # If codec available, attempt compress (preferred)
        if codec_ready:
            try:
                out = model.compress(x_padded, int(args.qp))
                if isinstance(out, dict) and 'bit_stream' in out and out['bit_stream'] is not None:
                    bit_stream = out['bit_stream']
                    had_bitstream = True
                else:
                    # no bitstream returned (some models return recon instead)
                    bit_stream = b''
                    had_bitstream = False
            except Exception as e:
                # compress failed despite codec seeming ready. Fall back to differentiable recon.
                print(f"Warning: model.compress() failed for frame {i}: {e}")
                codec_ready = False  # disable for subsequent frames
                # fall through to differentiable recon
        if not had_bitstream:
            # differentiable recon path (we still output an empty .bin)
            x_hat_padded = differentiable_recon(model, x_padded)
            # attempt to update dpb with last good reconstructed frame (already done inside differentiable_recon)
            bit_stream = b''

        # Save bitstream file (possibly empty)
        bin_fname = out_dir / f"frame_{i:05d}.bin"
        try:
            with open(bin_fname, 'wb') as f:
                if isinstance(bit_stream, (bytes, bytearray)):
                    f.write(bit_stream)
                elif hasattr(bit_stream, 'tobytes'):
                    f.write(bit_stream.tobytes())
                elif bit_stream is None:
                    pass
                else:
                    try:
                        f.write(bytes(bit_stream))
                    except Exception:
                        pass
        except Exception as e:
            print(f"Failed to write bitstream for frame {i} to {bin_fname}: {e}")

        # Save a reconstructed PNG as well (so you can visually inspect)
        try:
            if had_bitstream:
                # if we had a real bitstream, optionally decompress to get x_hat via model.decompress
                try:
                    sps = {'height': H, 'width': W, 'ec_part': 0}
                    if isinstance(bit_stream, (bytes, bytearray)):
                        dec = model.decompress(bit_stream, sps, int(args.qp))
                        x_hat = dec.get('x_hat', x)
                        # if decoder returned padded size, crop
                        x_hat = x_hat[..., :H, :W]
                    else:
                        # fallback to differentiable recon
                        x_hat = differentiable_recon(model, x_padded)
                        x_hat = x_hat[..., :H, :W]
                except Exception:
                    x_hat = differentiable_recon(model, x_padded)
                    x_hat = x_hat[..., :H, :W]
            else:
                # no bitstream — x_hat from differentiable recon
                x_hat = differentiable_recon(model, x_padded)
                x_hat = x_hat[..., :H, :W]
        except Exception:
            x_hat = x_padded[..., :H, :W]

        # clip & save PNG
        out_np = (np.clip(x_hat[0].cpu().numpy().transpose(1,2,0), 0.0, 1.0) * 255.0).round().astype(np.uint8)
        Image.fromarray(out_np).save(out_dir / f"frame_{i:05d}.png")

        # assemble manifest entry
        manifest["frame_meta"].append({
            "index": i,
            "filename": str(bin_fname.name),
            "orig_height": int(H),
            "orig_width": int(W),
            "pad_h": int(pad_h),
            "pad_w": int(pad_w),
            "qp": int(args.qp),
            "had_bitstream": bool(had_bitstream)
        })

    # Save manifest
    manifest_path = out_dir / "manifest.json"
    with open(manifest_path, 'w') as f:
        json.dump(manifest, f, indent=2)

    print("Encoding complete. Wrote", len(manifest["frame_meta"]), "bitstreams to", out_dir)
    print("Manifest saved to", manifest_path)

if __name__ == "__main__":
    main()
