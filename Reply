import torch, numpy as np
from PIL import Image
from glob import glob
from src.models.video_model import DMC as VideoModel
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

# load model + checkpoint
model = VideoModel().to(device).eval()
ckpt = "./checkpoints_finetune_lambda0.01/best_epoch000.pth.tar"
if os.path.exists(ckpt):
    ck = torch.load(ckpt, map_location="cpu")
    sd = ck.get("state_dict", ck)
    model.load_state_dict({k.replace("module.",""): v for k,v in sd.items()}, strict=False)
    print("Loaded checkpoint:", ckpt)
else:
    print("Checkpoint not found:", ckpt)

# pick first validation frame
files = sorted(glob("data/frames/val/**/*.png", recursive=True))
if len(files) == 0:
    files = sorted(glob("data/frames/train/**/*.png", recursive=True))
print("sample file:", files[0])
img = Image.open(files[0]).convert("RGB")
arr = (np.asarray(img, dtype=np.float32)/255.0).transpose(2,0,1)
x = torch.from_numpy(arr).unsqueeze(0).to(device)  # [1,C,H,W]

# Try: model.compress
print("\n== TRY compress() ==")
try:
    out = model.compress(x, 0)
    print("compress returned:", type(out), "keys:", out.keys() if isinstance(out, dict) else None)
    if isinstance(out, dict) and 'bit_stream' in out:
        bs = out['bit_stream']
        print("bit_stream len (bytes):", len(bs) if bs is not None else None)
    if isinstance(out, dict) and 'x_hat' in out:
        xhat = out['x_hat']
        print("compress returned x_hat shape:", xhat.shape)
except Exception as e:
    print("compress raised:", repr(e))

# Try: feature_adaptor -> feature_extractor -> encoder -> decoder -> recon_generation
print("\n== TRY encoder/decoder submodules ==")
with torch.no_grad():
    # feature adaptor (may rely on dpb[0])
    try:
        # ensure dpb exists
        if not hasattr(model, "dpb") or len(model.dpb)==0:
            try:
                zeros = torch.zeros_like(x)
                model.clear_dpb()
                model.add_ref_frame(frame=zeros, increase_poc=False)
                print("Initialized dpb with zero frame.")
            except Exception:
                model.dpb = []
                model.add_ref_frame(frame=zeros, increase_poc=False)
                print("Initialized dpb (fallback).")
    except Exception as e:
        print("dpb init failed:", e)

    try:
        feat_adapt = model.apply_feature_adaptor()
        print("apply_feature_adaptor() ->", None if feat_adapt is None else tuple(feat_adapt.shape))
    except Exception as e:
        print("apply_feature_adaptor() raised:", e)
        feat_adapt = None

    try:
        qf = model.q_feature[0:1] if hasattr(model, "q_feature") else None
        ctx, ctx_t = model.feature_extractor(feat_adapt if feat_adapt is not None else x, qf)
        print("feature_extractor -> ctx", None if ctx is None else tuple(ctx.shape), "ctx_t", None if ctx_t is None else tuple(ctx_t.shape))
    except Exception as e:
        print("feature_extractor raised:", e)
        ctx, ctx_t = (None, None)

    try:
        q_enc = model.q_encoder[0:1] if hasattr(model, "q_encoder") else None
        y = model.encoder(x, ctx if ctx is not None else feat_adapt if feat_adapt is not None else x, q_enc)
        print("encoder -> y shape:", None if y is None else tuple(y.shape))
    except Exception as e:
        print("encoder raised:", e)
        y = None

    try:
        q_dec = model.q_decoder[0:1] if hasattr(model, "q_decoder") else None
        q_recon = model.q_recon[0:1] if hasattr(model, "q_recon") else None
        if y is not None:
            feat_dec = model.decoder(y, ctx if ctx is not None else feat_adapt, q_dec)
            print("decoder -> feat_dec shape:", tuple(feat_dec.shape))
            x_hat1 = model.recon_generation_net(feat_dec, q_recon).clamp(0,1)
            print("recon_generation_net -> x_hat1 shape:", tuple(x_hat1.shape))
        else:
            print("y is None -> cannot run decoder path")
            x_hat1 = None
    except Exception as e:
        print("decoder/recon raised:", e)
        x_hat1 = None

# Compare final outputs
print("\n== Comparisons ==")
# wrapper encode_decode_sequence if available
try:
    from training import encode_decode_sequence
    encdec_out = encode_decode_sequence(model, x.unsqueeze(1), qp=0)  # [B,T,C,H,W] with T=1
    xhat_encdec = encdec_out["x_hat"][:,0]
    print("encode_decode_sequence returned shape", xhat_encdec.shape)
except Exception as e:
    print("encode_decode_sequence call failed:", e)
    xhat_encdec = None

# choose candidate x_hats to compare
candidates = {"compress_xhat": None, "decoder_xhat": None, "encdec_xhat": None}
if 'out' in locals() and isinstance(out, dict):
    candidates["compress_xhat"] = out.get("x_hat", None)
candidates["decoder_xhat"] = x_hat1
candidates["encdec_xhat"] = xhat_encdec

for k,v in candidates.items():
    if v is None:
        print(f"{k}: None")
        continue
    eq = torch.equal(x, v)
    close = torch.allclose(x, v, atol=1e-8)
    diff = (x - v).abs()
    print(f"{k}: shape={tuple(v.shape)}, equal={eq}, allclose={close}, diff_min={float(diff.min())}, diff_max={float(diff.max())}, diff_mean={float(diff.mean())}")
