model.update() failed or not needed (continuing fallback).")

    # clear DPB
    try:
        model.clear_dpb()
    except Exception:
        model.dpb = []

    # find meta files
    metas = sorted(glob.glob(os.path.join(args.encoded_dir, "frame_*.meta.json")))
    if len(metas) == 0:
        raise SystemExit("No meta files found in encoded-dir")

    bad_frames = 0
    last_good_frame = None

    for meta_file in tqdm(metas, desc="Decoding frames"):
        with open(meta_file, 'r') as f:
            meta = json.load(f)
        base = os.path.basename(meta_file).replace('.meta.json','')
        bin_path = os.path.join(args.encoded_dir, f"{base}.bin")
        idx_str = base.split('_')[-1]
        out_png = os.path.join(args.out_dir, f"frame_{idx_str}.png")
        orig_h = int(meta.get('height'))
        orig_w = int(meta.get('width'))
        pad_h = int(meta.get('pad_h', 0))
        pad_w = int(meta.get('pad_w', 0))
        qp = int(meta.get('qp', 0))
        raw_xhat = bool(meta.get('raw_xhat', False))

        # If raw_xhat -> load PNG generated by encoder or fallback identity
        if raw_xhat:
            raw_png = os.path.join(args.encoded_dir, f"{base}.raw_xhat.png")
            if os.path.exists(raw_png):
                img = Image.open(raw_png).convert('RGB')
                img.save(out_png)
                last_good_frame = out_png
                continue
            else:
                # no raw file; attempt fallback: identity (not ideal)
                print(f"Warning: raw_xhat true but {raw_png} missing. Using black frame.")
                black = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)
                Image.fromarray(black).save(out_png)
                last_good_frame = out_png
                continue

        # read bitstream bytes
        if not os.path.exists(bin_path):
            print(f"Warning: bin file missing for {meta_file}, creating black frame")
            black = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)
            Image.fromarray(black).save(out_png)
            bad_frames += 1
            continue

        with open(bin_path, 'rb') as f:
            bs = f.read()

        # Try decompress via model.decompress
        try:
            sps = {'height': orig_h + pad_h, 'width': orig_w + pad_w, 'ec_part': meta.get('ec_part', 0)}
            dec = model.decompress(bs, sps, qp)
            x_hat = dec.get('x_hat', None)
            if x_hat is None:
                raise RuntimeError("decompress returned no x_hat")
            # ensure device and detach
            if isinstance(x_hat, torch.Tensor):
                x_hat = x_hat.detach().cpu()
            else:
                # if numpy array
                x_hat = torch.from_numpy(np.array(x_hat)).float()

            # crop to original size
            x_hat = crop_from_padded(x_hat, orig_h, orig_w)
            out_np = (np.clip(x_hat[0].numpy().transpose(1,2,0), 0.0, 1.0) * 255.0).round().astype(np.uint8)
            Image.fromarray(out_np).save(out_png)
            last_good_frame = out_png

            # update DPB if model expects it (best-effort)
            try:
                # attempt to add frame to dpb similar to encoder
                t = torch.from_numpy(out_np.astype(np.float32)/255.0).permute(2,0,1).unsqueeze(0).to(device)
                t_padded = t
                # add as reference frame
                try:
                    model.add_ref_frame(feature=None, frame=t_padded, increase_poc=True)
                except Exception:
                    try:
                        model.add_ref_frame(frame=t_padded, increase_poc=True)
                    except Exception:
                        pass
            except Exception:
                pass

        except Exception as e:
            # decompression failed: save last_good_frame (if available) or black frame
            bad_frames += 1
            print(f"Warning: decompress failed for {meta_file}: {e}")
            if last_good_frame is not None:
                # copy last good to current
                from shutil import copyfile
                copyfile(last_good_frame, out_png)
            else:
                black = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)
                Image.fromarray(black).save(out_png)

    print("Decoding finished. Reconstructed frames saved to", args.out_dir)
    print("Bad frames replaced:", bad_frames)

if __name__ == "__main__":
    main()


---

Important notes & tips

Pad multiple: I used 64 by default to match DCVC internals; change --pad-mult if you used a different padding strategy when training/encoding.

Model/extension compatibility: The encoder uses model.compress() (which relies on the entropy coder library). The decoder uses model.decompress() — both machines must have matching model code and the MLCodec_extensions_cpp entropy coder compiled/installed to decode bitstreams. If the decoder cannot run the entropy coder extension, use the fallback approach (save raw quantized tensors or raw x_hat PNGs from the encoder) — encoder already handles missing compress() by producing a raw_xhat.

Metadata: The .meta.json stores original height/width and padding so decoder can correctly crop.

DPB: the scripts call model.add_ref_frame/model.clear_dpb best-effort so temporal priors behave similarly on encoder & decoder. If your encoder uses a different DPB strategy (GOP/I-frame insertion), ensure decoder receives the same DPB resets / sequence boundaries.

Testing locally: Before distributing, test decompress(compress(x)) locally to confirm bit-exact or close reconstructions.

Transferring files: For many frames you may prefer bundling e.g. tar/zip or using object storage (S3) rather than many individual files.



---

If you want, I can:

Add an option to the encoder to save quantized latent tensors instead of bitstreams (for usage on decoders without entropy coder).

Provide an example that writes a single container file (one big .tar or .npz) instead of per-frame files.

Show how to export the decoder neural nets to TorchScript/ONNX so the decoder can run without the original Python repo (still requires entropy decoder or you must send latents).


Which follow-up would you like?
