# padded_reconstruct_clip_unique_plot.py
import os, math, glob, tqdm, time, uuid
import numpy as np
from PIL import Image
import torch
import torch.nn.functional as F
from src.models.video_model import DMC as VideoModel

# live-plot imports
from IPython.display import display, update_display
import matplotlib
matplotlib.use('module://matplotlib_inline.backend_inline')
import matplotlib.pyplot as plt

# ----------------------
# Config / Paths (edit)
# ----------------------
ckpt_path = "./checkpoints_new_lambda0.01/best_epoch002.pth.tar"
frames_dir = "data/frames/train/clip_01"
out_dir = "outputs/recon_frames/new_train/1_clip_01_padded"
os.makedirs(out_dir, exist_ok=True)

# Optional: provide a human run name to help identify this plot (can be '')
run_name = ""  # e.g. "run_lr1e-4" or leave empty

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

# Load model
model = VideoModel().to(device).eval()
if os.path.exists(ckpt_path):
    ck = torch.load(ckpt_path, map_location="cpu")
    sd = ck.get("state_dict", ck)
    model.load_state_dict({k.replace("module.",""): v for k,v in sd.items()}, strict=False)
    print("Loaded checkpoint:", ckpt_path)
else:
    print("Warning: checkpoint not found:", ckpt_path)

# Helper: PSNR
def mse_to_psnr(mse, max_val=1.0):
    if mse <= 0:
        return float("inf")
    return 10.0 * math.log10((max_val**2) / mse)

# helper to compute padding so H and W become multiples of 16
def get_pad_amount(height, width, mult=16):
    pad_h = (mult - (height % mult)) % mult
    pad_w = (mult - (width % mult)) % mult
    # pad format for torch.nn.functional.pad: (left, right, top, bottom)
    left = 0
    right = pad_w
    top = 0
    bottom = pad_h
    return (left, right, top, bottom)

# get frame list
frame_paths = sorted(glob.glob(os.path.join(frames_dir, "*.png")))
if len(frame_paths) == 0:
    raise SystemExit(f"No frames found in {frames_dir}")

# initialize dpb
try:
    model.clear_dpb()
except Exception:
    model.dpb = []

psnr_list = []
mse_list = []

# --------------------------
# Create a unique display id
# --------------------------
# Use a timestamp + uuid + optional run_name so each execution shows a new figure in the notebook
timestamp_ms = int(time.time() * 1000)
unique_token = uuid.uuid4().hex[:8]
_display_id_str = f"psnr_plot_{timestamp_ms}_{unique_token}"
if run_name:
    _display_id_str = f"{_display_id_str}_{run_name}"

print("Live PSNR plot display_id:", _display_id_str)

# Prepare the matplotlib figure (we will display it and then update with update_display)
fig, ax = plt.subplots(figsize=(10, 3))
ax.set_title("PSNR per frame (live) â€” " + (_display_id_str if run_name == "" else run_name))
ax.set_xlabel("frame index")
ax.set_ylabel("PSNR (dB)")
ax.grid(True)
line, = ax.plot([], [], marker='o', markersize=3, linestyle='-', linewidth=0.7)
ax.set_xlim(0, max(10, len(frame_paths)))
ax.set_ylim(0, 50)

# display once (this creates a persistent output cell for this run)
try:
    display(fig, display_id=_display_id_str)
    plt.close(fig)  # avoid duplicate static figure below the live output
except Exception:
    # If display/update not available (running as a script outside notebook), ignore
    pass

# --------------------------
# Main per-frame loop
# --------------------------
for i, p in enumerate(tqdm.tqdm(frame_paths, desc="Frames")):
    im = Image.open(p).convert("RGB")
    arr = np.asarray(im, dtype=np.float32)/255.0
    H, W = arr.shape[0], arr.shape[1]

    x = torch.from_numpy(arr.transpose(2,0,1))[None,...].to(device)  # [1,C,H,W]

    pad_h = (16 - (H % 16)) % 16
    pad_w = (16 - (W % 16)) % 16
    pad = (0, pad_w, 0, pad_h)
    if pad_w != 0 or pad_h != 0:
        x_padded = F.pad(x, pad, mode='replicate')
    else:
        x_padded = x

    # For first frame ensure dpb has a zero frame with same padded dims
    if i == 0:
        zeros = torch.zeros_like(x_padded)
        try:
            model.clear_dpb()
        except Exception:
            model.dpb = []
        try:
            model.add_ref_frame(frame=zeros, increase_poc=False)
        except Exception:
            try:
                model.add_ref_frame(feature=None, frame=zeros, increase_poc=False)
            except Exception:
                model.dpb = []
                model.add_ref_frame(frame=zeros, increase_poc=False)

    # run best-effort differentiable encode-decode path (no entropy coder)
    with torch.no_grad():
        try:
            feat_adapt = model.apply_feature_adaptor()
        except Exception:
            try:
                feat_in = F.pixel_unshuffle(x_padded, 8)
            except Exception:
                feat_in = x_padded
            try:
                feat_adapt = model.feature_adaptor_i(feat_in)
            except Exception:
                feat_adapt = feat_in

        ctx = None; ctx_t = None
        if hasattr(model, "feature_extractor"):
            try:
                qf = model.q_feature[0:1] if hasattr(model,"q_feature") else None
                ctx, ctx_t = model.feature_extractor(feat_adapt, qf)
            except Exception:
                ctx, ctx_t = (None, None)

        y = None
        if hasattr(model, "encoder"):
            try:
                q_enc = model.q_encoder[0:1] if hasattr(model,"q_encoder") else None
                y = model.encoder(x_padded, ctx if ctx is not None else feat_adapt, q_enc)
            except Exception:
                y = None

        x_hat_padded = x_padded
        if y is not None and hasattr(model, "decoder") and hasattr(model, "recon_generation_net"):
            try:
                q_dec = model.q_decoder[0:1] if hasattr(model,"q_decoder") else None
                q_recon = model.q_recon[0:1] if hasattr(model,"q_recon") else None
                feat_dec = model.decoder(y, ctx if ctx is not None else feat_adapt, q_dec)
                x_hat_padded = model.recon_generation_net(feat_dec, q_recon).clamp(0,1)
                try:
                    model.add_ref_frame(feature=feat_dec, frame=x_hat_padded, increase_poc=True)
                except Exception:
                    try:
                        model.add_ref_frame(frame=x_hat_padded, increase_poc=True)
                    except Exception:
                        pass
            except Exception:
                x_hat_padded = x_padded

    # crop back to original H,W
    x_hat = x_hat_padded[..., :H, :W]

    mse = F.mse_loss(x_hat, x, reduction="mean").item()
    psnr = mse_to_psnr(mse)
    mse_list.append(mse)
    psnr_list.append(psnr)

    # save reconstructed frame while guarding against invalid values
    out_np = (np.clip(x_hat[0].cpu().numpy().transpose(1,2,0), 0.0, 1.0) * 255.0).round().astype(np.uint8)
    Image.fromarray(out_np).save(os.path.join(out_dir, f"frame_{i:05d}.png"))

    if i < 3:
        print(f"frame {i}: mse={mse:.6e} psnr={psnr if psnr!=float('inf') else 'inf'} saved -> {os.path.join(out_dir, f'frame_{i:05d}.png')}")

    # --------------------------
    # Update the live PSNR plot in-place using the unique display id
    # --------------------------
    try:
        line.set_xdata(np.arange(len(psnr_list)))
        line.set_ydata(np.array(psnr_list))
        ax.relim()
        ax.autoscale_view()
        update_display(fig, display_id=_display_id_str)
        plt.pause(0.001)
    except Exception:
        # silently ignore plotting errors (so logs remain clean)
        pass

# summary
finite_psnrs = [p for p in psnr_list if np.isfinite(p)]
avg_mse = float(np.mean(mse_list)) if len(mse_list) > 0 else float('nan')
avg_psnr = float(np.mean(finite_psnrs)) if len(finite_psnrs)>0 else float('nan')
print("Done. frames:", len(frame_paths), "avg_mse:", avg_mse, "avg_psnr (finite only):", avg_psnr)
print("Saved reconstructed frames to:", out_dir)
